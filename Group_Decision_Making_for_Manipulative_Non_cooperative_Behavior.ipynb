{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "O3bKygj2Go0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx7gMRHvE8yw"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Defining global variables\n",
        "'''\n",
        "\n",
        "# evaluation threshold\n",
        "beta = 0.2\n",
        "# consensus threshold\n",
        "gamma = 0.75 # changed from .75 to test\n",
        "# deviation threshold\n",
        "alpha = 0.20\n",
        "# efficiency threshold\n",
        "chi = 0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m - no. of experts\n",
        "m = 5\n",
        "# n - no. of alternatives\n",
        "n = 4\n",
        "# P - 3d preference relation matrix of dimension m*n*n (FPR)\n",
        "P = [\n",
        "    [[0.5, 0.44, 0.40, 0.36],\n",
        "[0.56, 0.5, 0.79, 0.58],\n",
        "[0.60, 0.21, 0.5, 0.98],\n",
        "[0.94, 0.42, 0.02, 0.5]],\n",
        "\n",
        "[[0.5, 0.22, 0.99, 0.39],\n",
        "[0.78, 0.5, 0.37, 0.32],\n",
        "[0.01, 0.63, 0.5, 0.35],\n",
        "[0.61, 0.68, 0.65, 0.5]],\n",
        "\n",
        "[[0.5, 0.14, 0.11, 0.01],\n",
        "[0.86, 0.5, 0.44, 0.05],\n",
        "[0.89, 0.56, 0.5, 0.06],\n",
        "[0.99, 0.95, 0.94, 0.5]],\n",
        "\n",
        "[[0.5, 0.11, 0.62, 0.55],\n",
        "[0.89, 0.5, 0.82, 0.04],\n",
        "[0.38, 0.18, 0.5, 0.98],\n",
        "[0.45, 0.96, 0.02, 0.5]],\n",
        "\n",
        "[[0.5, 0.97, 0.43, 0.18],\n",
        "[0.03, 0.5, 0.56, 0.50],\n",
        "[0.57, 0.44, 0.5, 0.49],\n",
        "[0.82, 0.50, 0.51, 0.5]]\n",
        "]\n",
        "\n",
        "P = np.array(P)\n",
        "print(\"P global shape: \", P.shape)\n",
        "# weights - weight of experts 1*m\n",
        "weights = [0.3, 0.2, 0.2, 0.1, 0.2]\n",
        "weights = np.array(weights)\n",
        "# ST - interaction strength graph (m*m)\n",
        "# trustMat = np.random.rand(5,5)\n",
        "# trustMat = np.round(trustMat, 1)\n",
        "# np.fill_diagonal(trustMat, 0)\n",
        "# trustMat\n",
        "\n",
        "trustMat = np.array([[0. , 0.7, 0.2, 0.3, 0.5],\n",
        "       [0.1, 0. , 0.4, 0.9, 0.7],\n",
        "       [0.5, 0.4, 0. , 0. , 0.2],\n",
        "       [0.1, 0.8, 0. , 0. , 0.3],\n",
        "       [0.7, 0.3, 0.2, 0.4, 0. ]])\n",
        "\n",
        "\n",
        "# trustMat = [[0, 0.3, 0.4, 0, 0.2], \n",
        "# \t [0.4, 0, 0.1, 0.1, 0.2],\n",
        "# \t [0.3, 0.5, 0, 0.1, 0.2],\n",
        "#    [0, 0, 0, 0, 0],\n",
        "#    [0.1, 0.1, 0.2, 0.2, 0]\n",
        "#    ]\n",
        "# trustMat = np.array(trustMat)\n",
        "\n",
        "selfTrust = np.random.rand(5)\n",
        "selfTrust = np.round(selfTrust, 1)\n",
        "\n",
        "moderatorTrust = np.random.rand(5)\n",
        "moderatorTrust = np.round(moderatorTrust, 1)"
      ],
      "metadata": {
        "id": "aLBV_3A3G5gj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b946f0-a0f5-4298-8a86-4e27657551e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P global shape:  (5, 4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collective_matrix(w, P):  # w is normalized weights after update_MBweights for consensus measuring, and original for finding manipulating experts\n",
        "  Pc = np.zeros((n,n))\n",
        "  for k in range(m):\n",
        "    Pc = Pc + w[k]*P[k]\n",
        "  return Pc\n",
        "# print(collective_matrix(weights,P))"
      ],
      "metadata": {
        "id": "7Zt73OIJHf7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v9iZHI69_DDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NC1(k,Pc,P):\n",
        "  # print(\"P shape in nc1: \", P.shape)\n",
        "  temp = np.abs(P[k] - Pc)  #for the case i=j, both Pij and Pcij are 0.5, \n",
        "  # so the difference does not contribute to sum, same as in paper\n",
        "  nc1 = np.sum(temp)\n",
        "  nc1 = nc1/(n*n - n)\n",
        "  return nc1"
      ],
      "metadata": {
        "id": "6WiEQO5iLp2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NC2(k):\n",
        "  phi_k = np.sum(P[k],1) # 1D array having sum of preference of each alternative\n",
        "  # print(\"phi_k: \", phi_k)\n",
        "  l = -1\n",
        "  nc2= -999\n",
        "  for i in range(n):\n",
        "    min_val = 999\n",
        "    for j in range(n):\n",
        "       if j!=i:   \n",
        "        diff = phi_k[i]-phi_k[j] \n",
        "        min_val = min(min_val, diff)\n",
        "    if min_val>nc2:\n",
        "      nc2 = min_val\n",
        "      l = i\n",
        "  return nc2,l\n"
      ],
      "metadata": {
        "id": "d-G8tq9FOKe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collectiveNc2(Pc,l):\n",
        "  # integer having sum of collective preference of lth alternative\n",
        "  phi_xl = 0\n",
        "  for i in range(n):\n",
        "    phi_xl += Pc[l][i]\n",
        "  phi_xj = np.sum(Pc,1) # 1D array having sum of collective preference of each alternative=\n",
        "  collective_nc2 = 999\n",
        "  for i in range(n):\n",
        "    if phi_xl > phi_xj[i]:\n",
        "      collective_nc2 = min(collective_nc2, phi_xl-phi_xj[i])\n",
        "  return collective_nc2"
      ],
      "metadata": {
        "id": "GK6D3WgbZnqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sub-network detection method based on WeChat-like interaction network\n",
        "# Algorithm 1\n",
        "def detectSubgroups(trustMat, k=1): #trustMat is the mxm trust matrix\n",
        "  m = trustMat.shape[0]\n",
        "\t# step 1\n",
        "  C = np.identity(m) + trustMat\n",
        "  for i in range(m):\n",
        "    for j in range(m):\n",
        "      if C[i][j] > 0:\n",
        "       C[i][j] = 1\n",
        "  #print(C)\n",
        "  #step 2\n",
        "  Ebar = [] \n",
        "  nc = []\n",
        "  for i in range(m):\n",
        "   nci = np.count_nonzero(C[:,i])\n",
        "   #print(trustMat[:,i])\n",
        "   if nci > 0:\n",
        "   \tEbar.append((nci, i))\n",
        "  Ebar.sort(reverse=True)\n",
        "  # print(Ebar)\n",
        "  #step 3\n",
        "  groups = []\n",
        "  while Ebar:\n",
        "    ejk = Ebar[0][1]\n",
        "    ncjk = Ebar[0][0]\n",
        "    EkLeader = []\n",
        "    for i in Ebar:\n",
        "      ncp = i[0]\n",
        "      ep = i[1]\n",
        "      if ncjk == ncp and C[ejk][ep]==1:\n",
        "        EkLeader.append(ep)\n",
        "    # E bar  = Ebar \\ EkLeader\n",
        "    Ebar = [i for i in Ebar if i[1] not in EkLeader]\n",
        "    print(\"Group \", k)\n",
        "    k+=1\n",
        "    print(\"EkLeader:\", EkLeader)\n",
        "    #print(Ebar)\n",
        "    EkFollower = []\n",
        "    for i in Ebar:\n",
        "      ei = i[1]\n",
        "      for j in EkLeader:\n",
        "        if C[ei][j] == 1:\n",
        "          EkFollower.append(ei)\n",
        "          break\n",
        "    #print(Ebar)\n",
        "    # E bar  = Ebar \\ EkFollower\n",
        "    Ebar = [i for i in Ebar if i[1] not in EkFollower]\n",
        "    print(\"EkFollower:\", EkFollower)\n",
        "    #print(Ebar)\n",
        "    EkLeader.sort()\n",
        "    EkFollower.sort()\n",
        "    Ek = [EkLeader, EkFollower]\n",
        "    groups.append(Ek)\n",
        "  return groups\n",
        "    "
      ],
      "metadata": {
        "id": "fqUo5pXTN0wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Procedure to update weights of manipulators\n",
        "def sigmah(h,collective_nc2,Pc,P):\n",
        "  nc2h = NC2(h)[0]\n",
        "  num = collective_nc2/nc2h\n",
        "  num = num*(1-NC1(h,Pc,P))\n",
        "  den = 1+ (1 - (collective_nc2/nc2h))*NC1(h,Pc,P)\n",
        "  # print(\"expert: \", h, \"nc2h: \", nc2h, \"collective: \", collective_nc2)\n",
        "  # print(\"num: \", num, \"den: \", den )\n",
        "  return num/den\n",
        "\n",
        "def update_MBweights(weights, nc2l, Pc, manipulatorIndices,P):\n",
        "  for i in manipulatorIndices:\n",
        "    sigma = sigmah(i,nc2l,Pc,P)\n",
        "    weights[i] = weights[i]*sigma"
      ],
      "metadata": {
        "id": "bl3YK82yU7B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize weights of other DM's \n",
        "def normalize_weights(MBexperts, weights):\n",
        "  mb_experts_sum = 0\n",
        "  for expert in MBexperts:\n",
        "    mb_experts_sum += weights[expert]\n",
        "  nfactor = (1-mb_experts_sum)/(m - len(MBexperts))\n",
        " \n",
        "\n",
        "  for i in range(m):\n",
        "    if i not in MBexperts:\n",
        "      weights[i] *= nfactor\n",
        "  # print(\"in normalize: \", weights, \"factor: \", nfactor)\n",
        "  return weights"
      ],
      "metadata": {
        "id": "_4omwR2e_Uwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def consensus_degree_expert(k, Pc):\n",
        "  temp = 1-(np.abs(P[k] - Pc))  #for the case i=j, both Pij and Pcij are 0.5, so the difference does not contribute to sum, same as in paper\n",
        "  consensus_degree = np.sum(temp)/(n*(n-1))\n",
        "  return consensus_degree"
      ],
      "metadata": {
        "id": "vlGme2zI3pgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lambda_den(group):\n",
        "  w_sum = 0\n",
        "  for l in group:\n",
        "    for expert in l:\n",
        "        w_sum+=weights[expert]\n",
        "  return w_sum\n",
        "def consensus_degree_groups(groups,Pc):\n",
        "  ACD = []\n",
        "  for group in groups:\n",
        "    w_sum = lambda_den(group)\n",
        "    cd_group = 0\n",
        "    for l in group:\n",
        "      for expert in l:\n",
        "        lambdak = weights[expert]/w_sum\n",
        "        cd_group += lambdak*consensus_degree_expert(expert,Pc)\n",
        "      ACD.append(cd_group)\n",
        "    return ACD\n",
        "\n",
        "def consensus_degree_groups(groups,Pc):\n",
        "  ACD = []\n",
        "  for group in groups:\n",
        "    w_sum = lambda_den(group)\n",
        "    cd_group = 0\n",
        "    for l in group: # l is for the two lists, leader and follower\n",
        "      for expert in l:\n",
        "        lambdak = weights[expert]/w_sum\n",
        "        cd_group += lambdak*consensus_degree_expert(expert,Pc)\n",
        "    ACD.append(cd_group)\n",
        "  return ACD"
      ],
      "metadata": {
        "id": "6O537yCL3ogu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# influence matrix matrix\n",
        "def getInfluenceMatrix(group, trustMat = trustMat, selfTrust = selfTrust, moderatorTrust = moderatorTrust):\n",
        "  mk = len(group)\n",
        "  TD = np.zeros((mk, mk+1))\n",
        "  z = []\n",
        "  # print(trustMat.shape)\n",
        "  for i in range(mk):\n",
        "    for j in range(mk):\n",
        "      TD[i][j] = trustMat[group[i]][group[j]]\n",
        "    TD[i][mk] = moderatorTrust[group[i]]\n",
        "    z.append(selfTrust[group[i]])\n",
        "\n",
        "  #normalize TD\n",
        "  sum_of_rows = TD.sum(axis=1)\n",
        "  TD = TD / sum_of_rows[:, np.newaxis]\n",
        "  \n",
        "  # obtain influence matrix W for this group\n",
        "  q = np.eye(mk) - np.diag(z)\n",
        "  W = np.c_[np.diag(z), np.zeros(mk)] + np.matmul(q, TD) #equation 14\n",
        "  return W"
      ],
      "metadata": {
        "id": "4mvz0Kc1L-av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getNextPreference(group, Pt, Pct):\n",
        "  # here and in getInfluenceMatrix, group is assumed to be a list of experts, not list of list having leaders and followers\n",
        "  Wk = getInfluenceMatrix(group)\n",
        "\n",
        "  # obtain pij, of size (mk+1)*(m)*(m), current preferences of these experts and Pc\n",
        "  pij = []\n",
        "  for i in group:\n",
        "    pij.append(Pt[i])\n",
        "  pij.append(Pct)\n",
        "  pij = np.array(pij)\n",
        "\n",
        "  #evolved preferences\n",
        "  pNext = []\n",
        "  mk = len(group)\n",
        "  for i in range(mk):   #obtain next preference of each expert as per eq 15\n",
        "    prefI = np.zeros((n,n))\n",
        "    for j in range(mk+1):\n",
        "      prefI += Wk[i][j]*pij[j]\n",
        "    pNext.append(prefI)\n",
        "  pNext = np.array(pNext) \n",
        "  # print(pNext.shape)\n",
        "\n",
        "\n",
        "  return np.array(pNext)\n",
        "    \n",
        "getNextPreference([1,2], P, collective_matrix(weights, P))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXUVDAy2f4Pv",
        "outputId": "0cd2445c-1e49-4a79-d150-60d940a96bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.5    , 0.2498 , 0.8016 , 0.3298 ],\n",
              "        [0.7502 , 0.5    , 0.4216 , 0.2994 ],\n",
              "        [0.1984 , 0.5784 , 0.5    , 0.3654 ],\n",
              "        [0.6882 , 0.7006 , 0.6346 , 0.5    ]],\n",
              "\n",
              "       [[0.5    , 0.19235, 0.2987 , 0.10735],\n",
              "        [0.80765, 0.5    , 0.45245, 0.1358 ],\n",
              "        [0.7013 , 0.54755, 0.5    , 0.1803 ],\n",
              "        [0.90615, 0.8642 , 0.8197 , 0.5    ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]"
      ],
      "metadata": {
        "id": "DEYiZpU3bGDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identifyNB(flatG,Pc,Pc_prev,P,Pprev):\n",
        "  NB = []\n",
        "  for k in flatG:\n",
        "    nc1 = NC1(k,Pc,P)\n",
        "    nc1_prev = NC1(k,Pc_prev,Pprev)\n",
        "    nc3 = (nc1_prev - nc1)/nc1_prev\n",
        "    if nc1 >= (1-gamma) and nc3 <= chi:\n",
        "      NB.append(k)\n",
        "  return NB"
      ],
      "metadata": {
        "id": "5pznfapkT3mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_NBweights(weights,NB,Pc,P):\n",
        "  for ek in NB:\n",
        "    weights[ek] = weights[ek]*(1-NC1(ek,Pc,P))"
      ],
      "metadata": {
        "id": "apvWNapYfmt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(Pc,i):\n",
        "  sum =0\n",
        "  for j in range(n):\n",
        "    sum+=Pc[i][j]\n",
        "  return sum\n"
      ],
      "metadata": {
        "id": "vC1lL7cMuI45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The main steps of the GDM method\n",
        "def GDM(P=P, trustMat = trustMat, weights=weights, alpha = alpha, beta = beta, gamma = gamma, chi = chi, t=0):\n",
        "  # see if the graph shows trust mat, or interaction strength from which trust mat is to be calculated \n",
        "  #step 1\n",
        "  groups = detectSubgroups(trustMat)\n",
        "  print(\"Sub-groups in interaction network are: \",groups)\n",
        "  #step 2\n",
        "  Pc = collective_matrix(weights, P)\n",
        "  print(\"Collective Matrix Pc: \", Pc)\n",
        "  #experts that greatly differ from other experts\n",
        "  R1experts = []\n",
        "  for k in range(m):\n",
        "    nc1k = NC1(k,Pc,P)\n",
        "    if nc1k >= alpha:\n",
        "      R1experts.append(k)\n",
        "  print(\"R1 experts: \",R1experts)\n",
        "  #experts that are inclined towards some alternative l\n",
        "  R2experts = []\n",
        "  MB = {}\n",
        "\n",
        "  for k in range(m):\n",
        "    nc2k, l = NC2(k)\n",
        "    # print(k, \":\", nc2k)\n",
        "    collectiveNC2 = collectiveNc2(Pc,l) #generally, we choose beta > nc2l, that has to be implemented\n",
        "    # print(\"collectiveNC2:\", collectiveNC2)\n",
        "    if nc2k >= beta:\n",
        "      R2experts.append((l,k))\n",
        "      if k in R1experts:\n",
        "        if l not in MB: MB[l] = [k]\n",
        "        else: MB[l].append(k)\n",
        "  print(\"R2 experts: \", R2experts)\n",
        "  # print(\"experts following R1 and R2 supporting some  alternative: \", MB)\n",
        "  #R3\n",
        "  groups = detectSubgroups(trustMat)\n",
        "  nGrps = len(groups)\n",
        "  MBexperts = {}  # dict having the alternative and corresponding manipulative experts\n",
        "\n",
        "  MBexpertsList = [] # list having all MBexperts\n",
        "  \n",
        "  for i in MB:\n",
        "    MBi = MB[i]\n",
        "    for ek in groups:\n",
        "      MBik = [j for j in MB[i] if j in ek[0] or j in ek[1]] # eq 6 - members in group Ek who follow R1 and R2 for alternative xi\n",
        "      if set(MBik) & set(ek[0]):  \n",
        "        # MBexperts += MBik #eq 7 - If these have an opinion leader, we say that these experts are involved in manipulative behaviour\n",
        "        if i not in MBexperts:\n",
        "          MBexperts[i] = MBik\n",
        "        else: MBexperts[i].exted(MBik)\n",
        "        MBexpertsList += MBik\n",
        "  print(\"Manipulating experts for alternatives: \", MBexperts)\n",
        "\n",
        "  '''Step 3: Update weights of Manipulating DMs, normalize weights of other DMs, \n",
        "  remove manipulators and obtain updated subgroups\n",
        "  ''' \n",
        "\n",
        "  MBorNBexists = True\n",
        "\n",
        "  #To get back to step 3, i.e keep updating weights until manipulative or non-coopertaive behaviour exists\n",
        "  while MBorNBexists:\n",
        "\n",
        "    # print(weights)\n",
        "    # Update weights\n",
        "    for alternative in MBexperts:\n",
        "      update_MBweights(weights, collectiveNc2(Pc, alternative), Pc, MBexperts[alternative],P)\n",
        "    # print(weights)\n",
        "    weights = normalize_weights(MBexpertsList, weights)\n",
        "    # print(\"normalized weights\", weights)\n",
        "    # remove manipulative experts from subgroups\n",
        "    for group in groups:\n",
        "      group[0]  = [i for i in group[0] if i not in MBexpertsList]\n",
        "      group[1] = [i for i in group[1] if i not in MBexpertsList]\n",
        "    # print(MBexpertsList)\n",
        "    # print(groups)\n",
        "\n",
        "    '''Step 4: Obtain updated collective matrix using equation 8, and consensus degree of each updated subgroup\n",
        "    '''\n",
        "    Pc = collective_matrix(weights, P)\n",
        "\n",
        "    # GLT - groups with consensus degree lower than gamma\n",
        "    ACD = consensus_degree_groups(groups,Pc)\n",
        "    # print(\"Aggregated consensus degree: \", ACD)\n",
        "    GLT = []\n",
        "    for i in range(len(groups)):\n",
        "      if(ACD[i]<gamma):\n",
        "        GLT.append(i)\n",
        "    # print(\"GLT: \",GLT)\n",
        "    # print(\"ACD: \", ACD)\n",
        "\n",
        "    GLT = [groups[0]]\n",
        "    # print(\"groups: \", groups)\n",
        "\n",
        "    '''Step 5: CRP for groups with consensus degree less than gamma\n",
        "    ''' \n",
        "    gamma = .95 #to test\n",
        "    for g in GLT:\n",
        "      # for subgroups with memeber in GLT (non outliers)\n",
        "      # print(g)\n",
        "      # print(\"flat\", flatten(g))\n",
        "      cdg = consensus_degree_groups([g], Pc)\n",
        "      # print(\"gamma: \",gamma, \"CD: \", cdg)\n",
        "      # if the consensus degree of this group has not reached threshold\n",
        "      r=0\n",
        "      while cdg[0] < gamma:\n",
        "        # print(cdg[0])\n",
        "      # for h in range(1):\n",
        "        r = r + 1\n",
        "        print(\"consensus degree after round\", r,\": \", cdg)\n",
        "        # obtain next evolution based on feedback\n",
        "        flatG = flatten(g)\n",
        "        Pnext = getNextPreference(flatG, P, Pc)\n",
        "\n",
        "        P_prev = P\n",
        "        # update P as per Pnext\n",
        "        for i in range(len(flatG)):\n",
        "          P[flatG[i]] = Pnext[i]\n",
        "        # update Pc \n",
        "        Pc_prev = Pc\n",
        "        Pc = collective_matrix(weights, P)\n",
        "        cdg = consensus_degree_groups([g], Pc)\n",
        "        # print(cdg)\n",
        "\n",
        "        ''' Step 6: Identify non cooperative behaviour\n",
        "        '''\n",
        "        NB = identifyNB(flatG,Pc,Pc_prev,P,P_prev)\n",
        "        if r == 1:\n",
        "          print(\"Experts with Non-Cooperative behaviour: \", NB)\n",
        "        \n",
        "        '''Step 7: If there are DMs with NC Behaviour, penalize weights using Algo 3 and repeat\n",
        "        '''\n",
        "        #complete this\n",
        "        # influenceMat =  getInfluenceMatrix(NB)  #NB contains non coopeartive beharioral experts in this group\n",
        "     \n",
        "        update_NBweights(weights,NB,Pc,P)\n",
        "        # if NC behavior exists, make it true so that the loop from step 3 continues\n",
        "        if NB: MBorNBexists = False\n",
        "\n",
        "  print(\"Final consensus degree: \", cdg)\n",
        "  \n",
        "  '''Step 9: Selection\n",
        "  '''\n",
        "  # selected = 0\n",
        "  # max_score = -999\n",
        "  # for i in range(n):\n",
        "  #   score_i = score(Pc,i)\n",
        "  #   print(i, \":\", score_i)\n",
        "  #   if(score_i>max_score):\n",
        "  #     max_score = score_i\n",
        "  #     selected = i\n",
        "\n",
        "  scores = [score(Pc, i) for i in range(n)]\n",
        "  print(\"Scores of alternatives are: \", scores)\n",
        "  print(\"Selected: \", scores.index(max(scores)))\n",
        "\n",
        "    \n",
        "\n",
        "  # if MBexperts:\n",
        "  #   #step 3\n",
        "  #   update_MBweights(weights, collectiveNC2(, Pc, MBexperts)\n",
        "  #   print(weights)\n",
        "GDM()"
      ],
      "metadata": {
        "id": "2lyBAm87TEn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a5b4427-c7db-4a7f-eaff-5b464acff65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group  1\n",
            "EkLeader: [4, 1, 0]\n",
            "EkFollower: [3, 2]\n",
            "Sub-groups in interaction network are:  [[[0, 1, 4], [2, 3]]]\n",
            "Collective Matrix Pc:  [[0.5   0.409 0.488 0.279]\n",
            " [0.591 0.5   0.593 0.352]\n",
            " [0.512 0.407 0.5   0.572]\n",
            " [0.811 0.648 0.428 0.5  ]]\n",
            "R1 experts:  [1, 2, 3]\n",
            "R2 experts:  [(3, 1), (3, 2), (1, 3), (3, 4)]\n",
            "Group  1\n",
            "EkLeader: [4, 1, 0]\n",
            "EkFollower: [3, 2]\n",
            "Manipulating experts for alternatives:  {3: [1, 2]}\n",
            "consensus degree after round 1 :  [0.8618918490830527]\n",
            "Experts with Non-Cooperative behaviour:  [0, 4, 3]\n",
            "consensus degree after round 2 :  [0.9048150063446329]\n",
            "consensus degree after round 3 :  [0.901638677272024]\n",
            "consensus degree after round 4 :  [0.9175960730312542]\n",
            "consensus degree after round 5 :  [0.9424930985576905]\n",
            "Final consensus degree:  [0.9703584666040109]\n",
            "Scores of alternatives are:  [0.3886659705628978, 0.40029633583256896, 0.32816057131411014, 0.523132495608055]\n",
            "Selected:  3\n"
          ]
        }
      ]
    }
  ]
}